# 基于涌现能力的蒸馏（黑盒蒸馏）

黑盒蒸馏意味着教师模型的输出是我们唯一能获取到的训练资源，所以黑盒蒸馏整体的思路分成两步，1. 从教师模型收集问答数据 2. 使用这些数据对学生模型进行微调。
这份教程会详细介绍三种涌现能力的主流蒸馏方式，以及分别介绍针对第一步和第二步的改进方向。


# 1. In-context learning 蒸馏

大模型的一大特有的能力是上下文学习(In-context learning, ICL)，即在**推理阶段**进行少样本学习。
上下文学习的能力是一种类似于“举一反三”的能力，我们可以在Prompt中先给出几个问-答示例，接着给出一个问题，
模型就能按照示例的格式和模式输出回答。
然而，由于算力限制，不可能将具有ICL能力的大模型部署到实时推理系统上。
有没有一种技术能够将大模型的ICL能力迁移到一个小模型中呢？这就是本节将要探讨的问题。

## 1.1 ICL
首先，让我们对ICL做一个形式化的定义：ICL是指输入给模型以下格式的内容：
```
x_1, y_1;
x_2, y_2;
x_3, 
```
模型会输出：
```
y_3
```

其中x表示问题，y表示回答。

示例的格式**不一定**在训练时见过，但是模型可以在推理时模仿其中的格式和模式，这就是ICL能力神奇的地方：只要在prompt前加几个例子，模型就能学到其中的格式和逻辑，实现了推理时的学习。

以下是一个简单的ICL例子：
![alt text](image-1.png)

模型成功模仿了示例中的回答思路和格式。

## 1.2 ICL 微调

ICL微调就是让模型的输出$y_3$的概率尽量大, 即在给定模型参数$\theta$, 示例1和2, 以及prompt 3时, 模型输出 $y_3$ 的概率 $p(y_3|x_3, (x_1, y_1, x_2, y_2), \theta)$ 越大越好。
为了计算稳定，可以转变为对数概率，即$log \space p(y_3|x_3, (x_1, y_1, x_2, y_2), \theta)$ 越大越好. 损失函数一般是求最小化，所以再添加一个负号：

$$
-log \space p(y_3|x_3, (x_1, y_1, x_2, y_2), \theta)
$$

上面这个例子有两个示例问答对，所以可以叫做 two-shot, 实际中也可以使用 zero-shot, one-shot, ...。
假设示例问答对的数量是k， k-shot 的示例问答我们可以记作 $S_k$，正式的问题记作 $x$，期望的回答记作 $y$，最终的损失函数可以写成
$$
-log \space p(y|x, S_k, \theta)
$$

以上是一条微调数据的损失，一般微调需要几千到上万条数据，每一条数据都有各自的$x, y, S^x_k$，其中$S^x_k$代表对应于问题 $x$ 的示例前缀。
所以微调时总的损失如下
$$
L_{ICL} = \Sigma_{(x,y)\in D} - log \space p(y|x, S^x_k, \theta)
$$

这就是ICL微调的损失函数。一般我们对针对同一个类型的任务收集许多数据微调，所以一个任务$\mathcal{T}$会对应一个数据集 $\mathcal{D_T}$, 所以针对任务$\mathcal{T}$微调的损失函数如下：

$$
L^{ICL}_\mathcal{T} = \Sigma_{(x,y)\in \mathcal{D_T}} - log \space p(y|x, S^x_k, \theta)
$$

## 1.3 Meta-ICL Tuning 和 MultiTask-ICL Tuning
上面我们讲了针对任务$\mathcal{T}$进行ICL微调的损失函数，而实际中往往不止在一单一任务上微调，以获得更好的泛化性能。
因此，对多个任务微调的总损失如下：

$$
L^{ICL}_\mathcal{T} = \Sigma_{(x,y)\in \mathcal{D_T}} - log \space p(y|x, S^x_k, \theta)
$$

# 2. 指令跟随蒸馏

## 2.1 指令跟随

我们知道大模型的主流训练范式有三步，第一步是预训练，第二步是指令微调，第三步是RLHF。指令跟随的能力是在第二步获得的。

仅仅经过预训练的大模型没有指令微调的能力，它只能续写用户Prompt。经过指令微调的模型具有指令跟随的能力，而不是续写用户的指令。

如何将指令跟随能力蒸馏到小模型中呢？容易想到的思路是从大模型收集若干<指令-回答>数据，然后用这些数据来微调小模型。
那么如何从大模型收集<指令-回答>数据呢？有没有成本低，效率高的方法？答案是Self-Instruct。

## 2.2 Self-Instruct 范式



# 3. 思维链蒸馏
和之前说的一样，我们可以从大模型收集<问题-回答>对，然后用这些数据来微调小模型。
但是这时数据收集要注意数据的质量。回答中要包含正确的推理，并且最好是对于一个问题有多样的推理路径。

以下是一个训练gpt2进行时间推理的例子。

## 步骤1：收集数据
从教师模型收集推理样本，作为训练数据。在问题后面，我们加上一句"Let's think step by step."

<span style="color:red">USER:</span> Q: <Question\> A: Let's think step by step.

<span style="color:green">ROBOT:</span> <Reasoning\>

<span style="color:red">USER:</span> Q: <Question> A: Let's think step by step. <Reasoning\>\nTherefore, the answer is

<span style="color:green">ROBOT:</span> <Answer\>

其中第三行的<Reasoning>针对一个问题多次运行后可能有不同的推理路径。

## 步骤2：数据格式化
我们把以上收集的数据整理成某种格式化的数据，让他们具有统一的格式，方便训练。比如可以使用如下的格式：

```python
    input_format = "<Question> ###"
    label_format = "<Reasoning> --> <Answer>"
```
## 步骤3：微调
这一步是普通的微调，Loss函数是交叉熵损失。



















# 参考资料
1. [In-context Learning Distillation: Transferring Few-shot Learning Ability of Pre-trained Language Models](http://arxiv.org/abs/2212.10670)
2. 交叉熵：https://blog.csdn.net/tsyccnh/article/details/79163834 
3. [Model Compression and Efficient Inference for Large Language Models: A Survey](http://arxiv.org/abs/2402.09748)
